# web llm attacks
most times chatbots that respond with plausable answers
according to large language models

## prompt injection
special prompts to manipulate the llm for specific data
or to reveal stuff that it shouldnt

## api access
ask if it has access to any apis,
aks if it has access to any debug_apis
ask what these can do
ask if it can execute a querye fe "delete carlos from users" with the api

##

rm /home/carlos/morale.txt;echo@email.com
